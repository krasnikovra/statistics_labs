\documentclass[12pt]{article}

\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage[
a4paper, includefoot,
left=20mm, right=10mm, top=20mm, bottom=20mm,
headsep=1cm, footskip=1cm
]{geometry}

\usepackage{amsfonts}
\usepackage{amsmath} 
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{indentfirst} 
\usepackage{graphicx}
\usepackage{csquotes} 
\usepackage[justification=centering]{caption}
\usepackage{float}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}

\DeclareMathOperator{\med}{med}
\DeclareMathOperator{\rad}{rad}
\DeclareMathOperator{\wid}{wid}
\DeclareMathOperator{\midd}{mid}
\DeclareMathOperator{\mode}{mode}

\graphicspath{{../figures}}

\begin{document}
	\begin{titlepage}
		\begin{center}
			\textsc{Санкт-Петербургский политехнический университет\\Петра Великого\\[5mm]
				Физико-механический институт\\[2mm]
				Кафедра «Прикладная математика»}
			
			\vfill
			
			\textbf{Отчет\\по лабораторной работе №10\\по дисциплине\\«Математическая статистика»
				\\[26mm]
			}
		\end{center}
		
		\noindent
		\hspace*{100mm} Выполнил студент:\\[3mm]
		\hspace*{100mm} Красников Роман Андреевич\\
		\hspace*{100mm} группа: 5030102/00101\\[10mm]
		\hspace*{100mm} Проверил:\\[3mm]
		\hspace*{100mm} к.ф.-м.н., доцент\\
		\hspace*{100mm} Баженов Александр Николаевич
		
		\vspace*{\fill}
		\begin{center}
			Санкт-Петербург\\2023 г.
		\end{center}
	\end{titlepage}
	
	\newpage
	\tableofcontents
	\newpage
	\listoffigures
	\newpage
	\listoftables
	\newpage
	
	\section{Постановка задачи}
	Дадим общую формулировку задачи восстановления функциональной зависимости. Пусть некоторая величина $y$ является функцией от независимых переменных $x_1, x_2, ..., x_m$:
	$$y = f(\beta, x)\eqno (1)$$
	где $x = (x_1, x_2, ..., x_m)$ является вектором независимых переменных, $\beta =(\beta_1, \beta_2, ..., \beta_p)$ — вектор параметров функции. Заметим, что переменные $x_1, x_2, ..., x_m$ также называются входными, а переменные $y_1$ —
	выходной.
	
	Задача восстановления функциональной зависимости заключается в том, чтобы, располагая набором значений $x$ и $y$, найти такие $\beta_1, \beta_2, ..., \beta_p$ в выражении (1), которые соответствуют конкретной
	функции $f$ из параметрического семейства.
	
	Если функция $f$ является линейной, то можно записать
	$$y = \beta_0 + \beta_1 x_1 + ... + \beta_m x_m\eqno (2)$$
	
	В общем случае результаты измерений величин $x_1, x_2, ..., x_m$ и $y$
	являются интервальнозначными
	$$x_1^{(k)}, x_2^{(k)}, ..., x_m^{(k)}\:и\:y^{k}.$$
	Индекс $k$ пробегает значения от 1 до $n$, равного полному числу измерений.
	\newline
	\newline
	\textbf{Определение 2.2.1} Брусом неопределенности $k$-го измерения функциональной зависимости будем называть интервальный вектор-брус, образованный интервальными результатами измерений с одинаковыми значениями индекса $k$ [1]:
	$$(x_{k1}, x_{k2}, ..., x_{km}, y_k)\subset\mathbb{R}^{m+1}, k=1, 2, ..., n. \eqno (3) $$
	Брус неопределенности измерения является прямым декартовым
	произведением интервалов неопределенности независимых переменных
	и зависимой переменной.
	\newpage
	\section{Теория}
	\textbf{Данные выборки.} Имеется выборка данных $\textbf{X}_1$ с интервальной
	неопределённостью. Число отсчётов в выборке равно 200.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 140 mm, height = 100 mm]{first.png}
		\caption{ Диаграмма рассеяния выборки $\textbf{X}_1$ с уравновешенным
			интервалом погрешности.}
		\label{fig:one}
	\end{figure}
	
	На Рис. 1 представлены данные с прибора [23] с учётом погрешности измерительного прибора.
	
	Построим линейную модель данных и посмотрим, насколько удачно
	она описывает линейный тренд.
	
	\textbf{Варьирование неопределённости измерений.} Если величину коррекции каждого интервального наблюдения выборки выражать коэффициентом его уширения $\omega_i\geq1$, а общее изменение выборки характеризовать суммой этих коэффициентов, то минимальная коррекция выборки в виде вектора коэффициентов $\omega = (\omega_1, ..., \omega_n)$, необходимая для совместности задачи построения зависимости $x = \beta_0 + \beta_1 * i$ может быть найдена решением задачи условной оптимизации
	$$найти \min\limits_{\omega, \beta} \sum\limits_{i=1}^{n} \omega_i \eqno (4)$$
	при ограничениях
	\[
	\begin{cases}
		mid\:x_i-\omega_i\epsilon_i\leq\beta_0 + \beta_1 * i\leq mid\:x_i+\omega_i\epsilon_i,\\
		\omega_i\geq1,
	\end{cases}
	i = 1, ..., n.\eqno (5)\]
	
	Результирующие значения коэффициентов $\omega_i$, строго превосходящие единицу, указывают на наблюдения, которые требуют уширения интервалов неопределённости для обеспечения совместности данных и модели.
	
	Проведём вычисление параметров линейной регрессии по данным
	интервальной выборки $\textbf{X}_1$ с использованием программ С.И.Жилина [8] и оформленных применительно к задаче на [23]. Синтаксис вызова программы
	$$[tau, w, yint] = DataLinearModel(input1, epsilon0) \eqno (6)$$
	В (6) входами программы служат значения $mid\:\textbf{X}_1$ и величин
	неопределённости $\epsilon$, а выходами tau — значения параметров регресии
	$\beta_0, \beta_1\:и\:w$ — вектор весов расширения интервалов.
	
	На Рис. 2 красным цветом приведена регрессионная прямая.
	
	Вычисления с использованием программы (6) дают следующие
	результаты для регрессионных коэффициентов
	$$\beta_0 = tau(1) = 4.7203e - 01,\eqno (7)$$
	$$\beta_1 = tau(2) =  4.0915e - 06.\eqno (8)$$
	Все компоненты вектора $\omega$ оказались равны 1, то есть, расширения интервалов измерений не понадобилось. Таким образом, величина (4)
	равна числу элементов выборки.
	$$\min\limits_{\omega, \beta} \sum\limits_{i=1}^{n} \omega_i = 200\eqno (9)$$
	
	Недостатком полученного решения с единичными значениями $\omega_i$
	является неучёт расстояний точек регрессионной зависимости до данных интервальной выборки. Таким образом, прямая с параметрами
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 100 mm]{second.png}
		\caption{ Диаграмма рассеяния выборки $\textbf{X}_1$ и регрессионная прямая
			по модели (4) и (5).}
		\label{fig:two}
	\end{figure}
	(7) и (8) «не чувствует» отклонений измерений от прямой на концах выборки — неопределённости измерений достаточно велики, чтобы
	покрыть этот эффект.
	
	\textbf{Варьирование неопределённости измерений с расширением и
		сужением интервалов.} Выясним, что даёт решение задачи оптимизации другим способом, с расширением и сужением интервалов.
	
	Поставим задачу условной оптимизации следующим образом:
	$$найти \min\limits_{\omega, \beta} \sum\limits_{i=1}^{n} \omega_i \eqno (10)$$
	при ограничениях
	\[
	\begin{cases}
		mid\:x_i-\omega_i\epsilon_i\leq\beta_0 + \beta_1 * i\leq mid\:x_i+\omega_i\epsilon_i,\\
		\omega_i\geq0,
	\end{cases}
	i = 1, ..., n.\eqno (11)\]
	
	Отличие постановки от (4) и (5) состоит в том, что интервалы
	измерений могут как расширяться в случае $\omega_i\geq1$, так и сужаться при
	$0\leq\omega_i\leq1$.
	Вычисление параметров линейной регрессии по данным интервальной выборки $\textbf{X}_1$ производится как и в случае (6) с использованием программ С.И.Жилина [8] и оформленных применительно к задаче на [23]. Синтаксис вызова программы
	$$[tau, w, yint] = DataLinearModelZ(input1, epsilon0)\eqno (12)$$
	Входы и выходы функции DataLinearModelZ такие же, как и для
	DataLinearModelZ (6). 
	
	На Рис. 3 красным цветом приведена регрессионная прямая.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 100 mm]{third.png}
		\caption{ Диаграмма рассеяния выборки $\textbf{X}_1$ и регрессионная прямая
			по модели (10) и (11)}
		\label{fig:three}
	\end{figure}
	Жёлтым цветом на Рис. 3 показаны скорректированные интервалы выборки $\textbf{X}_1$. Небольшая часть интервалов на границах области расширилась, а большинство интервалов в диапазоне замеров примерно от 20 до 180 — сузилось.
	
	Величина меры (4) уменьшилась более, чем в 4 раза.
	$$\min\limits_{\omega, \beta} \sum\limits_{i=1}^{n} \omega_i = 45.7\leq200\eqno (13)$$
	
	Таким образом, постановка задачи с возможностью одновременного
	увеличения и уменьшения радиусов неопределённости измерений позволяет более гибко подходить к задаче оптимизации.
	
	На Рис. 4 приведены графики векторов $\omega_0$ и $\omega_1$, полученных при
	использовании двух рассмотренных подходов.
	
	В конкретном случае график вектора $\omega_0$ для постановки задачи оптимизации (10) и (11) содержит большое количество информации.
	
	Например, задавшись каким-то порогом $\alpha$: $0<\alpha\leq1$, можно выделить области входного аргумента $\Psi$, в которых регрессионная зависимость хуже соотвествует исходным данным. Например:
	$$\Psi = \arg_i \omega_i \geq\alpha \eqno (14)$$
	Для конкретного примера имеем две области $\Psi$ в начале и конце области данных.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 120 mm, height = 90 mm]{fourth.png}
		\caption{ Векторы $\omega_1$ и $\omega_0$.}
		\label{fig:four}
	\end{figure}
	Для объективного использования этого приёма параметр $\alpha$ можно
	брать, например, из анализа гистограммы распределения вектора вектора $\omega$.
	
	Использование выделения «подозрительных» областей даёт основу для других приёмов. Например, для построения кусочно-линейной регрессионной зависимости.
	
	\textbf{Анализ регрессионных остатков.} В теоретико-вероятностной математической статистике анализ регрессионных остатков — один из приёмов оценки качества регрессии.
	
	Приведём пример пояснения этого приёма. «Если выбранная регрессионная модель хорошо описывает истинную зависимость, то остатки должны быть независимыми, нормально распределенными случайными величинами с нулевым средним, и в
	их значениях должен отсутствовать тренд. Анализ регрессионных остатков — это процесс проверки выполнения этих условий.»
	https://wiki.loginom.ru/articles/discrepancy.html
	
	В случае интервальных выборок мы не задаёмся вопросом о виде
	распределения остатков, а будем использовать те возможности которые
	появляются при описании объектов и результатов вычислений в виде
	интервалов.
	
	На Рис. 5 приведена диаграмма рассеяния регрессионных остатков выборки $\textbf{X}_1$ по модели (4) и (5).
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{fifth.png}
		\caption{ Диаграмма рассеяния по модели (4) и (5).}
		\label{fig:five}
	\end{figure}
	На Рис. 6 приведена диаграмма рассеяния регрессионных остатков выборки $\textbf{X}_1$ по модели (10) и (11).
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{sixth.png}
		\caption{ Диаграмма рассеяния регрессионных остатков выборки $\textbf{X}_1$
			по (10) и (11).}
		\label{fig:six}
	\end{figure}
	Из сравнения Рис. 5 и На Рис. 6 видно, что интервальные выборки остатков получились с весьма разными свойствами. Формально диаграмма рассеяния на первом рисунке `уже, то есть внешняя оценка более компактная. В то же время вторая диаграмма рассеяния выглядит более естественно.
	
	На Рис. 7 приведены графики частот элементарных подинтервалов при вычислении интервальной моды для двух моделей.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{seventh.png}
		\caption{ Частоты элементарных подинтервалов регрессионных
			остатков выборки $\textbf{X}_1$ по модели (4) и (5) — красный график, и
			(10) и (11) — синий график.}
		\label{fig:seven}
	\end{figure}
	Как и в случае анализа диаграмм рассеяния, второй график выглядит более естественно. Его внутренняя оценка существенно шире, что соотвествует большей устойчивостью к возмущениям данных.
	
	К остаткам можно применить и другие меры совместности оценки
	постоянной величины, описанные ранее.
	$$mode\:\textbf{X}^1 = ...\eqno (15)$$
	$$Ji(\textbf{X})^1 = ...\eqno (16)$$
	$$\vdots\eqno (17)$$
	$$mode\:\textbf{X}^2 = ...\eqno (18)$$
	$$Ji(\textbf{X})^2 = ...\eqno (19)$$
	$$\vdots\eqno (20)$$
	здесь $\textbf{X}^{1,2}$ — регрессионные остатки выборки $\textbf{X}_1$, вычисленные с использованием разных условий оптимизации.
	
	\textbf{Информационное множество задачи.} Интервальные оценки параметров.
	
	Один из главных вопросов при построении регрессии – оценивание
	её параметров. В зависимости от прикладных целей характер и назначение искомых оценок могут существенно разниться.
	
	Внешняя интервальная оценка параметра определяется минимальным и максимальным значениями, которых может достигать значение
	параметра в информационном множестве.
	
	В совокупности интервальные оценки параметров задают брус, описанный вокруг информационного множества и именуемый внешней интервальной оболочкой информационного множества:
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{8.png}
		\caption{ Информационное множество по модели (10) и (11),
			интервальная оболочка — красный брус.}
		\label{fig:eight}
	\end{figure}
	Проведём вычисление параметров линейной регрессии по данным
	интервальной выборки $\textbf{X}_1$ с использованием программ С.И.Жилина
	[8].
	
	Синтаксис вызова программ:
	
	Решение задачи линейного программирования
	$$SS = ir\_problem(A, x, max(w0)*epsilon, lb);$$
	Вершины информационного множества задачи
	построения интервальной регрессии
	$$vertices = ir\_beta2poly(SS);$$
	Внешние интервальные оценки параметров
	модели $y = \beta_1 + \beta_2 * x$
	$$b_{int} = ir\_outer(SS).$$
	
	Входами программы служат значения $mid\:\textbf{X}_1$ и величин неопределённости $\epsilon$, умноженные на расчётное уширение по модели (10) и (11), матрица $A$, составленная из нулевой и первой степеней номеров
	замеров, параметры условной оптимизации. Структура SS содержит
	значения параметров регресии.
	
	\textbf{Коридор совместных зависимостей.} Информационное множество задачи определяется в пространстве параметров. Каждая его точка задаёт зависимость в пространстве переменных. Множество всех таких моделей именуется коридором совместных зависимостей.
	
	Выше мы нашли внешние интервальные оценки параметров модели
	$$mid\:\beta_0 = [4.7193e - 01, 4.7221e - 01],\eqno (21)$$
	$$mid\:\beta_1 = [2.7304e - 06, 5.1571e - 06].\eqno (22)$$
	Подставляя значения (21) и (22) в уравнение регресии, получаем
	$$x(k) = mid\:\beta_0 + mid\:\beta_1 * k, \eqno (23)$$
	где $k$ — номер измерения.
	
	На Рис. 9 приведён коридор совместных зависимостей для модели (23). Визуально видно, что внутри коридор совместных зависимостей можно провести множество прямых.
	
	\textbf{Построение прогноза внутри и вне области данных.} Одним из способов использования регрессионной модели является предсказание значений выходной переменной для заданных значений входной. С помощью построенной выше модели (23) можно получить прогнозные значения выходной переменной в точках эксперимента.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{9.png}
		\caption{ Коридор совместных зависимостей (23).}
		\label{fig:nine}
	\end{figure}
	Ценность модели также заключается в возможности её употребления для предсказания выходной переменной в точках, где измерения не производились.
	
	Расширив область определения аргумента для модели (23), можно
	получить оценки для значений выходной переменной (экстраполяция).
	На Рис. 10 сплошной заливкой дан прогноз в том числе за пределами
	данных интервальной выборки $\textbf{X}_1$.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{10.png}
		\caption{ Коридор совместных зависимостей (23). Построение прогноза.}
		\label{fig:ten}
	\end{figure}
	Следует обратить внимание, что величина неопределённости прогнозов растёт по мере удаления от области, в которой производились исходные измерения. Это обусловлено видом коридора зависимостей, расширяющимся за пределами области измерений, и согласуется со
	здравым смыслом.
	
	\textbf{Уточнение структуры модели. Кусочно-линейная регрессионная зависимость.} Рис. 5 и Рис. 6 регресионных остатков свидетельствуют о том, что линейные регрессионные модели не вполне точно отражают характер зависимости для интервальной выборки $\textbf{X}_1$.
	Наиболее простым способом учёта этого факта является использование кусочно-линейная регрессионной зависимости.
	
	В разделе «Варьирование неопределённости измерений» были вычислены векторы весов $\omega$ расширения неопределённости измерений для достижения совместности — см. Рис. 4. Резкое возрастание весов $\omega$ на границах области определения свидетельствует о несоответствии данных и модели. Эти точки и можно взять как «угловые» для определения линейных участков.
	\begin{figure}[H]
		\centering
		\includegraphics[width = 150 mm, height = 90 mm]{11.png}
		\caption{ Кусочно-линейная регрессионная зависимость.}
		\label{fig:eleven}
	\end{figure}
	На Рис. 11 показан пример построения кусочно-линейная регрессионной зависимости и коридора соввместных зависимостей. После вычитания модели, можно переходить к анализу отстатков регресии и другим приёмам анализа.
	
	В более общей постановке ставится задача автоматического определения точек излома [29], [30]. Имеется программное обеспечение
	С.И.Жилина, реализующее идеи этого подхода.
	
	\section{Результаты}
	
	\subsection{Диаграмма рассеяния}
	
	Данные для выборки взяты из файла octave/Channel\_1\_500nm\_0\_23mm.csv, погрешность прибора $\epsilon = 10^{-4}$.
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{data_int.pdf}
		\caption{Диаграмма рассеяния выборки $\mathbf{X}_1$ с уравновешенным интервалом погрешности}
	\end{figure}

	\subsection{Варьирование неопределенности измерений}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{data_regr.pdf}
		\caption{Диаграмма рассеяния выборки $\mathbf{X}_1$ и регрессионная прямая
			по модели (2.35) и (2.36)}
	\end{figure}

	\begin{equation*}
		\sum\limits_{i=1}^n \omega_i = 200,\ \beta_0 = 0.334207, \beta_1 = 4.5 \cdot 10^{-6}
	\end{equation*}

	\subsection{Варьирование неопределённости измерений с расширением и сужением интервалов}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{data_regr_reduce.pdf}
		\caption{Диаграмма рассеяния выборки $\mathbf{X}_1$ и регрессионная прямая
			по модели (2.41) и (2.42)}
	\end{figure}

	\begin{equation*}
		\sum\limits_{i=1}^n \omega_i = 54.021,\ \beta_0 = 0.334301, \beta_1 = 3.5 \cdot 10^{-6}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{omegas.pdf}
		\caption{Векторы $\omega_1$ и $\omega_2$}
	\end{figure}
	
	\subsection{Анализ регресионных остатков}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{regr_residuals.pdf}
		\caption{Диаграмма рассеяния по модели (2.35) и (2.36)}
	\end{figure}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{regr_reduce_residuals.pdf}
		\caption{Диаграмма рассеяния регрессионных остатков выборки $\mathbf{X}_1$ по (2.41) и (2.42)}
	\end{figure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{mode_freq.pdf}
		\caption{Частоты элементарных подинтервалов регрессионных остатков выборки $\mathbf{X}_1$ по модели (2.35) и (2.36) — красный график, и (2.41) и (2.42) — синий график}
	\end{figure}
	
	\subsection{Информационное множество задачи}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{inform_set.pdf}
		\caption{Информационное множество по модели (2.41) и (2.42), интервальная оболочка — красный брус}
	\end{figure}

	\begin{equation*}
		\begin{gathered}
			\midd \boldsymbol{\beta}_0 = [0.334120, 0.334301]\\
			\midd \boldsymbol{\beta}_1 = [3.4 \cdot 10^{-6}, 5.3 \cdot 10^{-6}]
		\end{gathered}
	\end{equation*}

	\subsection{Коридор совместных зависимостей}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{corridor_of_joint_dep.pdf}
		\caption{Коридор совместных зависимостей (2.54)}
	\end{figure}
	
	\subsection{Построение прогноза внутри и вне области данных}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.65\linewidth]{corridor_of_joint_dep_zoomout.pdf}
		\caption{Коридор совместных зависимостей (2.54). Построение
			прогноза}
	\end{figure}
	
	\section{Обсуждение}
	
	\subsection{Варьирование неопределенности измерений}
	
	Для модели регрессии с $\omega_i \geq 1$ видим, что все $\omega_i = 1$, а регрессионная прямая действительно пересекает каждый отрезок без необходимости увеличения какого-либо из них.
	
	\subsection{Варьирование неопределенности измерений с расширением и сужением интервалов}
	
	Для модели регрессии с $\omega_i \geq 0$ видим, что для большинства интервалов $\omega_i < 1$, однако в начале и конце имеются выбросы $\omega_i \approx 1.5$. Также из рисунка видно, что регрессионная прямая пересекает уже не все интервалы. Это объясняется тем, что некоторые из них были увеличены, и регрессионная прямая пересекает измененные интервалы (желтые), притом пересекая увеличенный интервал она вовсе не обязана пересечь исходный.
	
	\subsection{Анализ регрессионных остатков}
	
	По результатам вычислений для регрессионных остатков можно сделать вывод, что мода регрессионных остатков по модели с $\omega_i \geq 0$ представляет собой более широкую окрестность нуля. Это означает, что регрессия по этой модели качественнее, нежели по модели $\omega_i \geq 1$.
	
	\subsection{Информационное множество задачи}
	
	Из графика для информационного множества задачи видим, что решение классических численных задач в интервальных постановках является вовсе не интервалом, а многогранным множеством. Притом независимые оценки для компонент решения можно дать, построив интервальную оболочку.
	
	\subsection{Коридор совместных зависимостей}
	
	По результатам построения коридора совместных зависимостей получено, как нетрудно видеть, множество, любая прямая, лежащая в котором, будет являться совместной регрессионной зависимостью для данной интервальной выборки.
	
	\subsection{Построение прогноза внутри и вне области данных}
	
	На уменьшенном рисунке для коридора совместных зависимостей видим, что он сужается ближе к центру выборки по $n$ и расширяется при отдалении от центра. Это поведение соответствует здравому смыслу.
	
	\section{Реализация}
	
	Лабораторная работа выполнена с помощью пакета GNU Octave 8.2.0. Использованы сторонние функции: 
	\begin{itemize}
		\item \url{https://github.com/AlexanderBazhenov/Solar-Data}
		\item \url{https://github.com/szhilin/octave-interval-examples}
	\end{itemize}
	
	Ссылка на исходный код лабораторной: \url{https://github.com/krasnikovra/statistics_labs/tree/cycle_10}
	
\end{document}}